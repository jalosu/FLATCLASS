{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25012f17",
   "metadata": {},
   "source": [
    "# Validación estadística y análisis de riesgo de misclasificación de un sistema de visión artificial para clasificación por talla en juveniles de lenguado\n",
    "\n",
    "```{admonition} Resumen ejecutivo\n",
    ":class: tip\n",
    "Este notebook (MyST dentro de `.ipynb`) desarrolla un manuscrito *paper-style* y **reproducible** para la validación de un sistema de visión artificial aplicado a juveniles de lenguado, con **objetivo principal de clasificación por talla** (pequeño, mediano, grande) y **objetivo secundario de biomasa agregada por clase**.\n",
    "El estudio se apoya en **1.250 observaciones** (5 experimentos consecutivos, 250 peces/día) y evalúa: exactitud, precisión, estabilidad inter-experimento, acuerdo metrológico (Bland–Altman), heterocedasticidad y un **análisis Monte Carlo del riesgo de misclasificación** inducido por la incertidumbre dimensional.\n",
    "```\n",
    "\n",
    "```{admonition} Requisitos para ejecutar\n",
    ":class: note\n",
    "- Archivo de datos: `Dataset_validacion_final.xlsx` (en el mismo directorio que este notebook, o ajusta la ruta).\n",
    "- Dependencias: `pandas`, `numpy`, `scipy`, `statsmodels`, `scikit-learn`, `matplotlib`, `openpyxl`.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945becfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 0) Imports y configuración\n",
    "# =========================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# --- Rutas de entrada/salida (adaptadas para Jupyter-Book) ---\n",
    "DATA_PATH = \"Dataset_validacion_final.xlsx\"\n",
    "\n",
    "# Carpeta donde guardaremos figuras y tablas para referenciarlas desde MyST\n",
    "STATIC_DIR = os.path.join(\"_static\", \"val_report\")\n",
    "FIG_DIR = STATIC_DIR\n",
    "TAB_DIR = os.path.join(STATIC_DIR, \"tables\")\n",
    "\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "os.makedirs(TAB_DIR, exist_ok=True)\n",
    "\n",
    "# Columnas esperadas\n",
    "COLS = {\n",
    "    \"exp\": \"exp\",\n",
    "    \"peso_real\": \"peso_g\",\n",
    "    \"L_real\": \"L_real\",\n",
    "    \"A_real\": \"A_real\",\n",
    "    \"L_av\": \"L_av\",\n",
    "    \"A_av\": \"A_av\",\n",
    "    \"peso_pred\": \"peso_pred\",\n",
    "    \"errL_pct\": \"errL_pct\",\n",
    "    \"errA_pct\": \"errA_pct\",\n",
    "    \"err_abs_peso\": \"err_abs_peso\",\n",
    "    \"err_rel_peso\": \"err_rel_peso\",\n",
    "}\n",
    "\n",
    "print(\"OK: imports cargados y carpetas preparadas:\", STATIC_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9bfa1",
   "metadata": {},
   "source": [
    "## Metodología\n",
    "\n",
    "### Diseño experimental\n",
    "\n",
    "El dataset contiene **1.250 registros** correspondientes a **cinco experimentos realizados en días consecutivos** (`exp = 1..5`), con **250 juveniles por experimento**. Cada individuo se mide en cinta mediante un sistema de visión artificial que entrega estimaciones de **longitud** y **anchura** en milímetros (`L_av`, `A_av`) y un **peso inferido** (`peso_pred`) derivado de un modelo alométrico previamente validado. Como referencia, se registra **longitud real** (`L_real`), **anchura real** (`A_real`) y **peso real** (`peso_g`).\n",
    "\n",
    "```{admonition} Objetivo del sistema\n",
    ":class: important\n",
    "El objetivo operativo principal es la **clasificación por talla** en tres categorías discretas (pequeño, mediano, grande) basada principalmente en las **dimensiones**.  \n",
    "El peso inferido se considera objetivo secundario para **biomasa agregada por clase**.\n",
    "```\n",
    "\n",
    "### Carga, preprocesado y control de calidad\n",
    "\n",
    "A continuación se implementa una rutina reproducible que: valida columnas, fuerza tipos numéricos, elimina filas incompletas y calcula residuales y errores absolutos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd44c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) Carga y preprocesado\n",
    "# =========================\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "\n",
    "# Validación de columnas\n",
    "missing = [c for c in COLS.values() if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Faltan columnas requeridas: {missing}\")\n",
    "\n",
    "# Forzar tipos numéricos\n",
    "for c in COLS.values():\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Eliminar filas con datos incompletos\n",
    "n0 = len(df)\n",
    "df = df.dropna(subset=list(COLS.values())).copy()\n",
    "n1 = len(df)\n",
    "\n",
    "# Residuales (visión - real) y errores absolutos\n",
    "df[\"errL_mm\"] = df[COLS[\"L_av\"]] - df[COLS[\"L_real\"]]\n",
    "df[\"errA_mm\"] = df[COLS[\"A_av\"]] - df[COLS[\"A_real\"]]\n",
    "df[\"errW_g\"]  = df[COLS[\"peso_pred\"]] - df[COLS[\"peso_real\"]]\n",
    "\n",
    "df[\"abs_errL_mm\"] = df[\"errL_mm\"].abs()\n",
    "df[\"abs_errA_mm\"] = df[\"errA_mm\"].abs()\n",
    "df[\"abs_errW_g\"]  = df[\"errW_g\"].abs()\n",
    "\n",
    "print(f\"Filas iniciales: {n0} | Filas tras limpiar nulos: {n1}\")\n",
    "print(\"Experimentos detectados:\", sorted(df[COLS[\"exp\"]].unique()))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47522e3b",
   "metadata": {},
   "source": [
    "### Normalización de errores relativos\n",
    "\n",
    "El dataset incluye errores relativos (`errL_pct`, `errA_pct`, `err_rel_peso`). En ocasiones se almacenan como fracción (0.05) o como porcentaje (5). Para evitar ambigüedad, se detecta la escala y se normaliza a **%** cuando procede.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eb6d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pct(series: pd.Series):\n",
    "    \"\"\"Normaliza fracción -> porcentaje si mediana(|x|) < 0.5.\"\"\"\n",
    "    s = series.astype(float).copy()\n",
    "    med = np.nanmedian(np.abs(s.values))\n",
    "    if med < 0.5:\n",
    "        return s * 100.0, True\n",
    "    return s, False\n",
    "\n",
    "df[\"errL_pct_norm\"], convL = normalize_pct(df[COLS[\"errL_pct\"]])\n",
    "df[\"errA_pct_norm\"], convA = normalize_pct(df[COLS[\"errA_pct\"]])\n",
    "df[\"errW_pct_norm\"], convW = normalize_pct(df[COLS[\"err_rel_peso\"]])\n",
    "\n",
    "print(\"Normalización aplicada:\", {\"errL_pct\": convL, \"errA_pct\": convA, \"err_rel_peso\": convW})\n",
    "df[[COLS[\"errL_pct\"], \"errL_pct_norm\", COLS[\"errA_pct\"], \"errA_pct_norm\", COLS[\"err_rel_peso\"], \"errW_pct_norm\"]].head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17208a8",
   "metadata": {},
   "source": [
    "### Metodología estadística\n",
    "\n",
    "Se calculan métricas estándar de validación (sesgo, MAE, RMSE, percentiles) y se evalúa:\n",
    "\n",
    "- **Consistencia global** (R²).\n",
    "- **Estabilidad inter-experimento** (Kruskal–Wallis sobre errores absolutos).\n",
    "- **Acuerdo metrológico** (Bland–Altman: sesgo y límites de acuerdo al 95%).\n",
    "- **Heterocedasticidad** (Breusch–Pagan) y dependencia con tamaño (Spearman).\n",
    "\n",
    "```{admonition} Enfoque talla-first\n",
    ":class: note\n",
    "En clasificación discreta, lo determinante es la incertidumbre dimensional **en mm** y su estabilidad; el peso se interpreta como variable secundaria para biomasa agregada por clase.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be95e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2) Métricas de validación\n",
    "# =========================\n",
    "def metrics(y_true, y_pred):\n",
    "    \"\"\"ME, MAE, RMSE, MedianAE, R2, MAPE, sMAPE, P90/P95 del error absoluto.\"\"\"\n",
    "    y_true = np.asarray(y_true, float)\n",
    "    y_pred = np.asarray(y_pred, float)\n",
    "    err = y_pred - y_true\n",
    "    eps = 1e-12\n",
    "    denom = np.where(np.abs(y_true) < eps, np.nan, y_true)\n",
    "    return {\n",
    "        \"n\": int(len(y_true)),\n",
    "        \"ME\": float(np.nanmean(err)),\n",
    "        \"MAE\": float(np.nanmean(np.abs(err))),\n",
    "        \"RMSE\": float(np.sqrt(np.nanmean(err**2))),\n",
    "        \"MedianAE\": float(np.nanmedian(np.abs(err))),\n",
    "        \"R2\": float(r2_score(y_true, y_pred)),\n",
    "        \"MAPE_%\": float(np.nanmean(np.abs(err / denom)) * 100.0),\n",
    "        \"sMAPE_%\": float(np.nanmean(2*np.abs(err) / (np.abs(y_true)+np.abs(y_pred)+eps)) * 100.0),\n",
    "        \"P90_AE\": float(np.nanquantile(np.abs(err), 0.90)),\n",
    "        \"P95_AE\": float(np.nanquantile(np.abs(err), 0.95)),\n",
    "    }\n",
    "\n",
    "overall = pd.DataFrame({\n",
    "    \"Longitud (mm)\": metrics(df[COLS[\"L_real\"]], df[COLS[\"L_av\"]]),\n",
    "    \"Anchura (mm)\": metrics(df[COLS[\"A_real\"]], df[COLS[\"A_av\"]]),\n",
    "    \"Peso (g)\": metrics(df[COLS[\"peso_real\"]], df[COLS[\"peso_pred\"]]),\n",
    "}).T\n",
    "\n",
    "overall.to_csv(os.path.join(TAB_DIR, \"tabla1_metricas_globales.csv\"))\n",
    "overall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75565d6",
   "metadata": {},
   "source": [
    "## Resultados generales\n",
    "\n",
    "A continuación se generan figuras de dispersión (real vs estimado) para inspección visual del ajuste y detección de desviaciones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a1a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 3) Figuras globales (Real vs Estimado)\n",
    "# =========================\n",
    "def save_fig(path):\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=250)\n",
    "    plt.close()\n",
    "\n",
    "# Longitud\n",
    "plt.figure()\n",
    "plt.scatter(df[COLS[\"L_real\"]], df[COLS[\"L_av\"]], s=10, alpha=0.5)\n",
    "mn = float(min(df[COLS[\"L_real\"]].min(), df[COLS[\"L_av\"]].min()))\n",
    "mx = float(max(df[COLS[\"L_real\"]].max(), df[COLS[\"L_av\"]].max()))\n",
    "plt.plot([mn, mx], [mn, mx])\n",
    "plt.xlabel(\"Longitud real (mm)\")\n",
    "plt.ylabel(\"Longitud visión (mm)\")\n",
    "plt.title(\"Longitud: real vs visión\")\n",
    "save_fig(os.path.join(FIG_DIR, \"fig1_L_real_vs_av.png\"))\n",
    "\n",
    "# Anchura\n",
    "plt.figure()\n",
    "plt.scatter(df[COLS[\"A_real\"]], df[COLS[\"A_av\"]], s=10, alpha=0.5)\n",
    "mn = float(min(df[COLS[\"A_real\"]].min(), df[COLS[\"A_av\"]].min()))\n",
    "mx = float(max(df[COLS[\"A_real\"]].max(), df[COLS[\"A_av\"]].max()))\n",
    "plt.plot([mn, mx], [mn, mx])\n",
    "plt.xlabel(\"Anchura real (mm)\")\n",
    "plt.ylabel(\"Anchura visión (mm)\")\n",
    "plt.title(\"Anchura: real vs visión\")\n",
    "save_fig(os.path.join(FIG_DIR, \"fig2_A_real_vs_av.png\"))\n",
    "\n",
    "# Peso\n",
    "plt.figure()\n",
    "plt.scatter(df[COLS[\"peso_real\"]], df[COLS[\"peso_pred\"]], s=10, alpha=0.5)\n",
    "mn = float(min(df[COLS[\"peso_real\"]].min(), df[COLS[\"peso_pred\"]].min()))\n",
    "mx = float(max(df[COLS[\"peso_real\"]].max(), df[COLS[\"peso_pred\"]].max()))\n",
    "plt.plot([mn, mx], [mn, mx])\n",
    "plt.xlabel(\"Peso real (g)\")\n",
    "plt.ylabel(\"Peso inferido (g)\")\n",
    "plt.title(\"Peso: real vs inferido\")\n",
    "save_fig(os.path.join(FIG_DIR, \"fig3_W_real_vs_pred.png\"))\n",
    "\n",
    "print(\"Figuras guardadas en:\", FIG_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093ac0f0",
   "metadata": {},
   "source": [
    "```{figure} _static/val_report/fig1_L_real_vs_av.png\n",
    ":name: fig-longitud\n",
    "Longitud real vs estimada por visión (línea y=x).\n",
    "```\n",
    "\n",
    "```{figure} _static/val_report/fig2_A_real_vs_av.png\n",
    ":name: fig-anchura\n",
    "Anchura real vs estimada por visión (línea y=x).\n",
    "```\n",
    "\n",
    "```{figure} _static/val_report/fig3_W_real_vs_pred.png\n",
    ":name: fig-peso\n",
    "Peso real vs peso inferido (línea y=x).\n",
    "```\n",
    "\n",
    "Como se aprecia en {numref}`fig-longitud` y {numref}`fig-anchura`, la dispersión residual es mínima, lo que respalda el uso para clasificación por talla. En {numref}`fig-peso` se observa mayor dispersión, coherente con el carácter secundario de la estimación de peso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dd44df",
   "metadata": {},
   "source": [
    "## Resultados inter-experimentos\n",
    "\n",
    "Se calculan métricas por experimento y se contrastan distribuciones de error absoluto mediante Kruskal–Wallis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 4) Métricas por experimento + tests inter-día\n",
    "# =========================\n",
    "rows = []\n",
    "for e, g in df.groupby(COLS[\"exp\"]):\n",
    "    mL = metrics(g[COLS[\"L_real\"]], g[COLS[\"L_av\"]])\n",
    "    mA = metrics(g[COLS[\"A_real\"]], g[COLS[\"A_av\"]])\n",
    "    mW = metrics(g[COLS[\"peso_real\"]], g[COLS[\"peso_pred\"]])\n",
    "    rows.append({\n",
    "        \"exp\": int(e),\n",
    "        \"L_MAE_mm\": mL[\"MAE\"], \"L_RMSE_mm\": mL[\"RMSE\"], \"L_ME_mm\": mL[\"ME\"],\n",
    "        \"A_MAE_mm\": mA[\"MAE\"], \"A_RMSE_mm\": mA[\"RMSE\"], \"A_ME_mm\": mA[\"ME\"],\n",
    "        \"W_MAE_g\": mW[\"MAE\"], \"W_RMSE_g\": mW[\"RMSE\"], \"W_ME_g\": mW[\"ME\"],\n",
    "        \"W_MAPE_%\": mW[\"MAPE_%\"],\n",
    "    })\n",
    "per_exp = pd.DataFrame(rows).sort_values(\"exp\")\n",
    "per_exp.to_csv(os.path.join(TAB_DIR, \"tabla2_metricas_por_experimento.csv\"), index=False)\n",
    "\n",
    "groups_absL = [g[\"abs_errL_mm\"].values for _, g in df.groupby(COLS[\"exp\"])]\n",
    "groups_absA = [g[\"abs_errA_mm\"].values for _, g in df.groupby(COLS[\"exp\"])]\n",
    "groups_absW = [g[\"abs_errW_g\"].values for _, g in df.groupby(COLS[\"exp\"])]\n",
    "\n",
    "kw_L = st.kruskal(*groups_absL)\n",
    "kw_A = st.kruskal(*groups_absA)\n",
    "kw_W = st.kruskal(*groups_absW)\n",
    "\n",
    "print(\"Kruskal-Wallis |ΔL| p:\", kw_L.pvalue)\n",
    "print(\"Kruskal-Wallis |ΔA| p:\", kw_A.pvalue)\n",
    "print(\"Kruskal-Wallis |ΔW| p:\", kw_W.pvalue)\n",
    "\n",
    "per_exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d77d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5) Boxplots por experimento (errores)\n",
    "# =========================\n",
    "# |ΔL|\n",
    "plt.figure()\n",
    "data = [df.loc[df[COLS[\"exp\"]] == e, \"abs_errL_mm\"] for e in sorted(df[COLS[\"exp\"]].unique())]\n",
    "plt.boxplot(data, labels=[str(e) for e in sorted(df[COLS[\"exp\"]].unique())])\n",
    "plt.xlabel(\"Experimento (día)\")\n",
    "plt.ylabel(\"|Error| longitud (mm)\")\n",
    "plt.title(\"Error absoluto de longitud por experimento\")\n",
    "save_fig(os.path.join(FIG_DIR, \"fig6_box_abs_errL_exp.png\"))\n",
    "\n",
    "# |ΔA|\n",
    "plt.figure()\n",
    "data = [df.loc[df[COLS[\"exp\"]] == e, \"abs_errA_mm\"] for e in sorted(df[COLS[\"exp\"]].unique())]\n",
    "plt.boxplot(data, labels=[str(e) for e in sorted(df[COLS[\"exp\"]].unique())])\n",
    "plt.xlabel(\"Experimento (día)\")\n",
    "plt.ylabel(\"|Error| anchura (mm)\")\n",
    "plt.title(\"Error absoluto de anchura por experimento\")\n",
    "save_fig(os.path.join(FIG_DIR, \"fig7_box_abs_errA_exp.png\"))\n",
    "\n",
    "# errW%\n",
    "plt.figure()\n",
    "data = [df.loc[df[COLS[\"exp\"]] == e, \"errW_pct_norm\"] for e in sorted(df[COLS[\"exp\"]].unique())]\n",
    "plt.boxplot(data, labels=[str(e) for e in sorted(df[COLS[\"exp\"]].unique())])\n",
    "plt.xlabel(\"Experimento (día)\")\n",
    "plt.ylabel(\"Error relativo de peso (%)\")\n",
    "plt.title(\"Error relativo de peso por experimento\")\n",
    "save_fig(os.path.join(FIG_DIR, \"fig5_box_errW_pct_exp.png\"))\n",
    "\n",
    "print(\"Boxplots guardados.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90875ff",
   "metadata": {},
   "source": [
    "```{figure} _static/val_report/fig6_box_abs_errL_exp.png\n",
    ":name: fig-errL-exp\n",
    "Distribución del error absoluto de longitud por experimento.\n",
    "```\n",
    "\n",
    "```{figure} _static/val_report/fig7_box_abs_errA_exp.png\n",
    ":name: fig-errA-exp\n",
    "Distribución del error absoluto de anchura por experimento.\n",
    "```\n",
    "\n",
    "```{figure} _static/val_report/fig5_box_errW_pct_exp.png\n",
    ":name: fig-errW-exp\n",
    "Distribución del error relativo de peso por experimento.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca903976",
   "metadata": {},
   "source": [
    "## Acuerdo metrológico y heterocedasticidad\n",
    "\n",
    "Se implementa Bland–Altman, Breusch–Pagan y correlaciones de Spearman.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c8d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 6) Bland–Altman + Heterocedasticidad + Spearman\n",
    "# =========================\n",
    "def bland_altman_stats(x, y):\n",
    "    x = np.asarray(x, float)\n",
    "    y = np.asarray(y, float)\n",
    "    diff = y - x\n",
    "    bias = float(np.mean(diff))\n",
    "    sd = float(np.std(diff, ddof=1))\n",
    "    loa_low = bias - 1.96 * sd\n",
    "    loa_high = bias + 1.96 * sd\n",
    "    return bias, sd, loa_low, loa_high\n",
    "\n",
    "def bland_altman_plot(x, y, unit, title, out_png):\n",
    "    mean = (np.asarray(x) + np.asarray(y)) / 2.0\n",
    "    diff = np.asarray(y) - np.asarray(x)\n",
    "    bias, sd, loa_low, loa_high = bland_altman_stats(x, y)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(mean, diff, s=10, alpha=0.5)\n",
    "    plt.axhline(bias)\n",
    "    plt.axhline(loa_low, linestyle=\"--\")\n",
    "    plt.axhline(loa_high, linestyle=\"--\")\n",
    "    plt.xlabel(f\"Media (real, visión) ({unit})\")\n",
    "    plt.ylabel(f\"Diferencia (visión - real) ({unit})\")\n",
    "    plt.title(title)\n",
    "    save_fig(out_png)\n",
    "    return bias, sd, loa_low, loa_high\n",
    "\n",
    "ba_L = bland_altman_plot(df[COLS[\"L_real\"]], df[COLS[\"L_av\"]], \"mm\", \"Bland–Altman Longitud\", os.path.join(FIG_DIR,\"fig8_BA_L.png\"))\n",
    "ba_A = bland_altman_plot(df[COLS[\"A_real\"]], df[COLS[\"A_av\"]], \"mm\", \"Bland–Altman Anchura\", os.path.join(FIG_DIR,\"fig9_BA_A.png\"))\n",
    "ba_W = bland_altman_plot(df[COLS[\"peso_real\"]], df[COLS[\"peso_pred\"]], \"g\", \"Bland–Altman Peso\", os.path.join(FIG_DIR,\"fig10_BA_W.png\"))\n",
    "\n",
    "def breusch_pagan(y_pred, y_true):\n",
    "    X = sm.add_constant(np.asarray(y_true, float))\n",
    "    model = sm.OLS(np.asarray(y_pred, float), X).fit()\n",
    "    lm, lm_p, f, f_p = sms.het_breuschpagan(model.resid, model.model.exog)\n",
    "    return float(lm), float(lm_p)\n",
    "\n",
    "bp_L = breusch_pagan(df[COLS[\"L_av\"]], df[COLS[\"L_real\"]])\n",
    "bp_A = breusch_pagan(df[COLS[\"A_av\"]], df[COLS[\"A_real\"]])\n",
    "bp_W = breusch_pagan(df[COLS[\"peso_pred\"]], df[COLS[\"peso_real\"]])\n",
    "\n",
    "sp_absW = st.spearmanr(df[COLS[\"peso_real\"]], df[\"abs_errW_g\"])\n",
    "sp_relW = st.spearmanr(df[COLS[\"peso_real\"]], df[\"errW_pct_norm\"].abs())\n",
    "\n",
    "print(\"Bland–Altman (L) bias/sd/LoA:\", ba_L)\n",
    "print(\"Bland–Altman (A) bias/sd/LoA:\", ba_A)\n",
    "print(\"Bland–Altman (W) bias/sd/LoA:\", ba_W)\n",
    "print(\"Breusch–Pagan p-values (LM):\", {\"L\": bp_L[1], \"A\": bp_A[1], \"W\": bp_W[1]})\n",
    "print(\"Spearman peso vs |ΔW|:\", sp_absW)\n",
    "print(\"Spearman peso vs |err_rel_peso|:\", sp_relW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b438878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuales de peso vs predicción\n",
    "plt.figure()\n",
    "plt.scatter(df[COLS[\"peso_pred\"]], df[\"errW_g\"], s=10, alpha=0.5)\n",
    "plt.axhline(0)\n",
    "plt.xlabel(\"Peso inferido (g)\")\n",
    "plt.ylabel(\"Residual (inferido - real) (g)\")\n",
    "plt.title(\"Residuales de peso vs predicción\")\n",
    "save_fig(os.path.join(FIG_DIR, \"fig4_resid_weight.png\"))\n",
    "print(\"Figura residual guardada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb62b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla de tests (para el paper)\n",
    "tests = pd.DataFrame([\n",
    "    {\"Prueba\":\"Kruskal-Wallis |ΔL| entre exp\", \"Estadístico\":kw_L.statistic, \"p\":kw_L.pvalue},\n",
    "    {\"Prueba\":\"Kruskal-Wallis |ΔA| entre exp\", \"Estadístico\":kw_A.statistic, \"p\":kw_A.pvalue},\n",
    "    {\"Prueba\":\"Kruskal-Wallis |ΔW| entre exp\", \"Estadístico\":kw_W.statistic, \"p\":kw_W.pvalue},\n",
    "    {\"Prueba\":\"Breusch–Pagan Longitud (L_av ~ L_real)\", \"Estadístico\":bp_L[0], \"p\":bp_L[1]},\n",
    "    {\"Prueba\":\"Breusch–Pagan Anchura (A_av ~ A_real)\", \"Estadístico\":bp_A[0], \"p\":bp_A[1]},\n",
    "    {\"Prueba\":\"Breusch–Pagan Peso (peso_pred ~ peso_g)\", \"Estadístico\":bp_W[0], \"p\":bp_W[1]},\n",
    "    {\"Prueba\":\"Spearman peso vs |ΔW|\", \"Estadístico\":sp_absW.statistic, \"p\":sp_absW.pvalue},\n",
    "    {\"Prueba\":\"Spearman peso vs |err_rel_peso|\", \"Estadístico\":sp_relW.statistic, \"p\":sp_relW.pvalue},\n",
    "])\n",
    "tests.to_csv(os.path.join(TAB_DIR, \"tabla3_tests.csv\"), index=False)\n",
    "tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd41c3",
   "metadata": {},
   "source": [
    "```{figure} _static/val_report/fig8_BA_L.png\n",
    ":name: fig-ba-L\n",
    "Bland–Altman para longitud.\n",
    "```\n",
    "\n",
    "```{figure} _static/val_report/fig9_BA_A.png\n",
    ":name: fig-ba-A\n",
    "Bland–Altman para anchura.\n",
    "```\n",
    "\n",
    "```{figure} _static/val_report/fig10_BA_W.png\n",
    ":name: fig-ba-W\n",
    "Bland–Altman para peso.\n",
    "```\n",
    "\n",
    "```{figure} _static/val_report/fig4_resid_weight.png\n",
    ":name: fig-resid-W\n",
    "Residuales del peso inferido vs predicción.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ef623c",
   "metadata": {},
   "source": [
    "## Simulación de riesgo de misclasificación por talla (Monte Carlo)\n",
    "\n",
    "```{admonition} Umbrales de clase\n",
    ":class: warning\n",
    "Si no dispones de umbrales oficiales en el dataset, el ejemplo usa terciles de `L_real` **solo como demostración reproducible**. Sustitúyelos por tus umbrales oficiales para resultados publicables definitivos.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009b9948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 7) Monte Carlo: probabilidad de misclasificación por incertidumbre dimensional\n",
    "# =========================\n",
    "def assign_class(x, t1, t2):\n",
    "    x = np.asarray(x, float)\n",
    "    out = np.empty_like(x, dtype=int)\n",
    "    out[x < t1] = 0\n",
    "    out[(x >= t1) & (x < t2)] = 1\n",
    "    out[x >= t2] = 2\n",
    "    return out\n",
    "\n",
    "# Umbrales DEMO: terciles de longitud real\n",
    "t1, t2 = np.quantile(df[COLS[\"L_real\"]].values, [1/3, 2/3])\n",
    "print(\"Umbrales DEMO (terciles L_real):\", t1, t2)\n",
    "\n",
    "# Distribución empírica del error de longitud (visión - real)\n",
    "err_samples = df[\"errL_mm\"].values\n",
    "\n",
    "def monte_carlo_misclassification(L_real, t1, t2, err_samples, n_mc=2000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    L_real = np.asarray(L_real, float)\n",
    "    true_cls = assign_class(L_real, t1, t2)\n",
    "\n",
    "    flips = np.zeros_like(true_cls, dtype=float)\n",
    "    for _ in range(n_mc):\n",
    "        e = rng.choice(err_samples, size=len(L_real), replace=True)\n",
    "        L_obs = L_real + e\n",
    "        obs_cls = assign_class(L_obs, t1, t2)\n",
    "        flips += (obs_cls != true_cls)\n",
    "\n",
    "    p_flip = flips / n_mc\n",
    "    return true_cls, p_flip\n",
    "\n",
    "true_cls, p_flip = monte_carlo_misclassification(df[COLS[\"L_real\"]].values, t1, t2, err_samples, n_mc=2000, seed=42)\n",
    "\n",
    "summary = pd.DataFrame({\"clase_true\": true_cls, \"p_flip\": p_flip})\n",
    "res_by_class = summary.groupby(\"clase_true\")[\"p_flip\"].agg(\n",
    "    mean=\"mean\",\n",
    "    median=\"median\",\n",
    "    p90=lambda x: np.quantile(x,0.90),\n",
    "    p95=lambda x: np.quantile(x,0.95),\n",
    "    n=\"size\"\n",
    ")\n",
    "res_by_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a2333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figura: riesgo por clase\n",
    "plt.figure()\n",
    "data = [summary.loc[summary[\"clase_true\"]==k, \"p_flip\"].values for k in [0,1,2]]\n",
    "plt.boxplot(data, labels=[\"pequeño\",\"mediano\",\"grande\"])\n",
    "plt.xlabel(\"Clase real (DEMO)\")\n",
    "plt.ylabel(\"Probabilidad de cambio de clase (Monte Carlo)\")\n",
    "plt.title(\"Riesgo de misclasificación inducido por error de longitud (DEMO)\")\n",
    "save_fig(os.path.join(FIG_DIR, \"fig11_mc_flip_by_class.png\"))\n",
    "print(\"Figura Monte Carlo guardada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116f7dcb",
   "metadata": {},
   "source": [
    "```{figure} _static/val_report/fig11_mc_flip_by_class.png\n",
    ":name: fig-mc-flip\n",
    "Riesgo de misclasificación (Monte Carlo) por clase (DEMO con terciles).\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52ba092",
   "metadata": {},
   "source": [
    "## Criterios de diseño y separación entre clases\n",
    "\n",
    "Sea \\(\\Delta L_{p95}\\) el percentil 95 del error absoluto de longitud. Para reducir el riesgo de misclasificación inducida por incertidumbre metrológica, se propone:\n",
    "\n",
    "```{math}\n",
    "\\Delta L_{\\text{clase}} \\ge 2 \\cdot \\Delta L_{p95}\n",
    "```\n",
    "\n",
    "```{admonition} Diseño robusto\n",
    ":class: important\n",
    "El diseño de umbrales debe basarse en percentiles (p95), no solo en medias.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f8626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 8) Cálculo de percentiles y chequeo del criterio (DEMO)\n",
    "# =========================\n",
    "dL_p95 = np.quantile(df[\"abs_errL_mm\"].values, 0.95)\n",
    "dA_p95 = np.quantile(df[\"abs_errA_mm\"].values, 0.95)\n",
    "delta_class_demo = t2 - t1\n",
    "\n",
    "print(\"ΔL_p95 (mm):\", dL_p95)\n",
    "print(\"ΔA_p95 (mm):\", dA_p95)\n",
    "print(\"ΔL_clase DEMO (t2-t1):\", delta_class_demo)\n",
    "print(\"Criterio 2*ΔL_p95:\", 2*dL_p95)\n",
    "print(\"¿Cumple DEMO?:\", delta_class_demo >= 2*dL_p95)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d51f6c",
   "metadata": {},
   "source": [
    "## Formalización matemática del acuerdo y la clasificación\n",
    "\n",
    "```{math}\n",
    "d_i = x_i^{vis} - x_i^{real}\n",
    "```\n",
    "\n",
    "```{math}\n",
    "\\bar{d} = \\frac{1}{n} \\sum_{i=1}^{n} d_i\n",
    "```\n",
    "\n",
    "```{math}\n",
    "LoA = \\bar{d} \\pm 1.96 \\cdot \\sigma_d\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639c7a81",
   "metadata": {},
   "source": [
    "## Apéndice metodológico\n",
    "\n",
    "Se incluyen supuestos, limitaciones y recomendaciones para reproducibilidad, así como la necesidad de sustituir umbrales DEMO por umbrales operativos oficiales para resultados finales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982b219e",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "El sistema presenta rendimiento dimensional excelente y estabilidad inter-experimento, adecuado para clasificación por talla. Bland–Altman cuantifica incertidumbre en mm; Monte Carlo conecta error continuo y riesgo discreto. El peso inferido se recomienda como variable secundaria para biomasa agregada por clase.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
