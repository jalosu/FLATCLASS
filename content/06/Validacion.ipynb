{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e694732b",
   "metadata": {},
   "source": [
    "# Validación en entorno industrial\n",
    "\n",
    "## Objetivo del estudio\n",
    "\n",
    "1. **Verificar la calidad metrológica** de las medidas morfométricas obtenidas por visión artificial (AV) frente a medidas reales (REAL).\n",
    "2. **Ajustar un modelo alométrico** para inferir peso a partir de longitud y anchura reales (modelo base), y aplicar la fórmula con dimensiones AV.\n",
    "3. **Cuantificar el error del peso inferido** como variable intermedia para clasificación por tamaños.\n",
    "4. **Analizar repetibilidad temporal** comparando resultados entre los 5 experimentos (días).\n",
    "5. Proponer **criterios razonables de aceptación** en producción acuícola, orientados a clasificación por tamaños y a justificación de **TRL** en memoria CDTI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c4f672-f347-4ad4-8ee6-905ed1c62bfa",
   "metadata": {},
   "source": [
    "````{admonition} Resumen \n",
    ":class: tip\n",
    "\n",
    "Este informe presenta la validación en entorno productivo real del sistema FLATCLASS, el prototipo automático de clasificación de alevines de lenguado (*Solea senegalensis*) basado en visión artificial. La validación se realizó en las instalaciones de Satistela S.A. ([Grupo Sea8](https://https://seaeight.eu/contacto/)) en Póvoa de Varzim (Portugal), mediante un protocolo multi-experimento diseñado para cuantificar: 1) la precisión en la clasificación por intervalos de talla (pequeño, mediano y grande), y 2) la exactitud en la estimación individual de biomasa de cada individuo detectado. El estudio se apoya en 1.250 observaciones (5 experimentos, 250 peces) y evalúa: exactitud, precisión, estabilidad inter-experimento, acuerdo metrológico (Bland–Altman), heterocedasticidad y un análisis Monte Carlo del riesgo de error de clasificación inducido por la incertidumbre dimensional.\n",
    "\n",
    "**Entregable**: E6.1  \n",
    "**Versión**: 1.0  \n",
    "**Autor**: Javier Álvarez Osuna  \n",
    "**Email**: javier.osuna@fishfarmfeeder.com  \n",
    "**ORCID**: [0000-0001-7063-1279](https://orcid.org/0000-0001-7063-1279)  \n",
    "**Licencia**: CC-BY-4.0  \n",
    "**Código proyecto**: IG408M.2025.000.000072\n",
    "\n",
    "```{figure} .././assets/FLATCLASS_logo_publicidad.png\n",
    ":width: 100%\n",
    ":align: center\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b495083-b857-42ce-95fa-d3a261b10d4e",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "El **objetivo general** planteado en la validación industrial de FLATCLASS reside en comprobar hasta qué punto el sistema de visión artificial desarrollado en el PT-1 es capaz de clasificar de forma fiable los juveniles de lenguado en las tres diferentes tallas (pequeño, normal, grande), teniendo en cuenta la incertidumbre inherente a las mediciones realizadas en condiciones reales de operación.\n",
    "\n",
    "Para ello, se han planteado los siguientes **objetivos específicos** orientados a analizar, de manera estructurada y cuantitativa, los distintos factores que condicionan la fiabilidad del proceso de clasificación. Estos objetivos permiten descomponer el problema global en aspectos medibles relacionados con la calidad metrológica de las estimaciones dimensionales, su estabilidad temporal, el grado de acuerdo con las medidas de referencia y el impacto práctico de los errores de medición sobre la decisión final de asignación de talla.\n",
    "\n",
    " 1. Caracterizar estadísticamente la exactitud y precisión de las mediciones dimensionales (longitud y anchura) obtenidas mediante el sistema de visión artificial, comparándolas con las medidas de referencia realizadas en laboratorio, con el fin de cuantificar el error medio, la dispersión y la presencia de posibles sesgos sistemáticos.\n",
    " 2.\tEvaluar el grado de acuerdo metrológico entre las medidas estimadas y las reales, utilizando análisis de Bland–Altman y métricas complementarias, para interpretar la incertidumbre del sistema directamente en unidades físicas relevantes para la clasificación por talla.\n",
    " 3.\tAnalizar la estabilidad temporal del sistema de medición y clasificación, comparando el comportamiento estadístico de los errores a lo largo de varios experimentos consecutivos realizados en días distintos, con el objetivo de detectar posibles derivas o variaciones operativas.\n",
    " 4.\tExaminar la relación entre el tamaño del individuo y la magnitud del error de medida, identificando posibles efectos de heterocedasticidad y dependencias con la talla que puedan influir en la fiabilidad de la clasificación en distintos rangos de tamaño.\n",
    " 5.\tEvaluar el desempeño del peso inferido como variable secundaria, analizando su precisión y variabilidad, y determinar su idoneidad para la estimación de biomasa agregada por clase de talla, en lugar de su uso como criterio primario de clasificación individual.\n",
    " 6.\tCuantificar el impacto práctico de la incertidumbre dimensional sobre la decisión de clasificación por talla, mediante simulaciones Monte Carlo que permitan estimar la probabilidad de cambio de clase inducida por los errores de medición.\n",
    " 7.\tIdentificar los rangos de talla más sensibles a la inestabilidad de clasificación, especialmente en torno a los umbrales entre clases, con el fin de caracterizar las zonas de mayor riesgo de asignación incorrecta.\n",
    " 8.\tProponer criterios estadísticos para el diseño y validación de los umbrales de clasificación por talla, basados en percentiles del error dimensional, que permitan reducir el riesgo de inestabilidad de clasificación en aplicaciones operativas.\n",
    " 9.\tProporcionar una base metodológica reproducible para la validación de sistemas de clasificación por visión artificial, integrando análisis metrológico, estadístico y de toma de decisiones, aplicable a otros contextos industriales y especies acuícolas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff24463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports y configuración ---\n",
    "import os\n",
    "import math\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 140)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ecabd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Carga del dataset ---\n",
    "path = \"Datos_experimentos_lenguado.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "df.shape, df.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6651314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Construcción de la variable Experimento ---\n",
    "# Asunción: 5 experimentos en bloques consecutivos de 250 registros\n",
    "n_per = 250\n",
    "df = df.copy()\n",
    "df[\"Experimento\"] = (np.arange(len(df)) // n_per) + 1\n",
    "\n",
    "df[\"Experimento\"].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144bc399",
   "metadata": {},
   "source": [
    "## Variables disponibles\n",
    "\n",
    "El dataset contiene:\n",
    "\n",
    "- `Peso (g)` : peso real (variable objetivo para validación)\n",
    "- `Longitud_REAL (mm)`, `Anchura_REAL (mm)` : medidas reales (referencia)\n",
    "- `Longitud_AV (mm)`, `Anchura_AV (mm)` : medidas obtenidas por visión artificial (AV)\n",
    "- `Error_longitud_% (AV-REAL)`, `Error_anchura_% (AV-REAL)` : errores relativos metrológicos ya calculados\n",
    "- `Longitud_px`, `Anchura_px` : medidas en píxeles (no utilizadas aquí para el modelo; el modelo opera en mm)\n",
    "- `Experimento` : identificador construido (E1..E5)\n",
    "\n",
    "### Enfoque\n",
    "1. Ajuste del modelo con medidas **REAL** (para estimación robusta de parámetros).\n",
    "2. Inferencia operativa usando dimensiones **AV**.\n",
    "3. Evaluación del error relativo del peso inferido frente al peso real.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46bfd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preparación: comprobaciones y columnas logarítmicas ---\n",
    "COL_W = \"Peso (g)\"\n",
    "L_real = \"Longitud_REAL (mm)\"\n",
    "A_real = \"Anchura_REAL (mm)\"\n",
    "L_av = \"Longitud_AV (mm)\"\n",
    "A_av = \"Anchura_AV (mm)\"\n",
    "\n",
    "# Verificar que todas las filas son válidas para log (positivas y no nulas)\n",
    "mask = (\n",
    "    df[[COL_W, L_real, A_real, L_av, A_av]].notna().all(axis=1) &\n",
    "    (df[[COL_W, L_real, A_real, L_av, A_av]] > 0).all(axis=1)\n",
    ")\n",
    "assert mask.all(), \"Hay filas no válidas para log; revisa el dataset.\"\n",
    "\n",
    "# Logs (para modelo alométrico)\n",
    "df[\"_log_w\"]   = np.log(df[COL_W])\n",
    "df[\"_log_Lr\"]  = np.log(df[L_real])\n",
    "df[\"_log_Ar\"]  = np.log(df[A_real])\n",
    "df[\"_log_Lav\"] = np.log(df[L_av])\n",
    "df[\"_log_Aav\"] = np.log(df[A_av])\n",
    "\n",
    "df[[COL_W, L_real, A_real, L_av, A_av, \"Experimento\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0317c",
   "metadata": {},
   "source": [
    "## Modelo alométrico (log–log) y corrección de retransformación\n",
    "\n",
    "Se ajusta un modelo lineal en el espacio logarítmico:\n",
    "\n",
    "\\[\n",
    "\\log(P) = b_0 + b_1 \\log(L) + b_2 \\log(A) + \\varepsilon\n",
    "\\]\n",
    "\n",
    "donde:\n",
    "\n",
    "- \\(P\\) es el peso (g),\n",
    "- \\(L\\) longitud (mm),\n",
    "- \\(A\\) anchura (mm).\n",
    "\n",
    "La predicción en espacio real se obtiene como:\n",
    "\n",
    "\\[\n",
    "\\hat{P} = \\exp(\\hat{y})\n",
    "\\]\n",
    "\n",
    "y, para reducir el sesgo por retransformación, se aplica una corrección multiplicativa tipo **smearing**:\n",
    "\n",
    "\\[\n",
    "\\hat{P}_{corr} = \\exp(\\hat{y}) \\cdot S, \\quad S = \\frac{1}{n}\\sum_i \\exp(\\hat{\\varepsilon}_i)\n",
    "\\]\n",
    "\n",
    "Este enfoque es especialmente útil en producción porque:\n",
    "- ofrece **interpretabilidad** y **estabilidad**,\n",
    "- es **eficiente computacionalmente** (Edge),\n",
    "- facilita auditoría y recalibraciones controladas si fuese necesario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba91f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ajuste del modelo con dimensiones REAL (global) ---\n",
    "Xr = sm.add_constant(df[[\"_log_Lr\", \"_log_Ar\"]])\n",
    "y = df[\"_log_w\"]\n",
    "\n",
    "model = sm.OLS(y, Xr).fit()\n",
    "print(model.summary())\n",
    "\n",
    "b0 = float(model.params[\"const\"])\n",
    "b1 = float(model.params[\"_log_Lr\"])\n",
    "b2 = float(model.params[\"_log_Ar\"])\n",
    "\n",
    "smearing = float(np.mean(np.exp(model.resid)))\n",
    "\n",
    "k = float(np.exp(b0))\n",
    "k_corr = k * smearing\n",
    "\n",
    "print(\"\\nParámetros:\")\n",
    "print(f\"b0={b0:.6f}, b1={b1:.6f}, b2={b2:.6f}\")\n",
    "print(f\"Smearing S={smearing:.6f}\")\n",
    "print(\"\\nFórmula operativa (smearing incluido):\")\n",
    "print(f\"Peso(g) = {k_corr:.12f} * L^{b1:.6f} * A^{b2:.6f}   (L,A en mm)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99178b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inferencia de peso usando dimensiones REAL y AV ---\n",
    "def pred_weight_from_logs(logL, logA):\n",
    "    return np.exp(b0 + b1 * logL + b2 * logA)\n",
    "\n",
    "# Predicción (naive) y corregida (smearing)\n",
    "df[\"Peso_inferido_REAL\"] = pred_weight_from_logs(df[\"_log_Lr\"], df[\"_log_Ar\"])\n",
    "df[\"Peso_inferido_REAL_smear\"] = df[\"Peso_inferido_REAL\"] * smearing\n",
    "\n",
    "df[\"Peso_inferido_AV\"] = pred_weight_from_logs(df[\"_log_Lav\"], df[\"_log_Aav\"])\n",
    "df[\"Peso_inferido_AV_smear\"] = df[\"Peso_inferido_AV\"] * smearing\n",
    "\n",
    "# Error relativo (%)\n",
    "df[\"Error_rel_peso_REAL_pct\"] = (np.abs(df[\"Peso_inferido_REAL_smear\"] - df[COL_W]) / df[COL_W]) * 100\n",
    "df[\"Error_rel_peso_AV_pct\"]   = (np.abs(df[\"Peso_inferido_AV_smear\"] - df[COL_W]) / df[COL_W]) * 100\n",
    "\n",
    "df[[COL_W, \"Peso_inferido_AV_smear\", \"Error_rel_peso_AV_pct\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9642ac",
   "metadata": {},
   "source": [
    "## Tablas de resultados (estadísticos y coberturas)\n",
    "\n",
    "Se generan tablas para:\n",
    "- estadísticos de peso real,\n",
    "- error metrológico de longitud/anchura (AV-REAL),\n",
    "- error del peso inferido con AV,\n",
    "- coberturas por umbrales (≤5%, ≤10%, ...),\n",
    "- resultados por experimento (repetibilidad inter-día),\n",
    "- resultados por rangos de peso (robustez por tamaño).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110213a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc(s: pd.Series) -> pd.Series:\n",
    "    return pd.Series({\n",
    "        \"N\": int(s.count()),\n",
    "        \"Media\": float(s.mean()),\n",
    "        \"Mediana\": float(s.median()),\n",
    "        \"Desv.Típ.\": float(s.std(ddof=1)),\n",
    "        \"P5\": float(s.quantile(0.05)),\n",
    "        \"P95\": float(s.quantile(0.95)),\n",
    "        \"Mín\": float(s.min()),\n",
    "        \"Máx\": float(s.max()),\n",
    "    })\n",
    "\n",
    "tab_peso = desc(df[COL_W]).to_frame(\"Peso (g)\")\n",
    "tab_errL = desc(df[\"Error_longitud_% (AV-REAL)\"]).to_frame(\"Error_longitud_% (AV-REAL)\")\n",
    "tab_errA = desc(df[\"Error_anchura_% (AV-REAL)\"]).to_frame(\"Error_anchura_% (AV-REAL)\")\n",
    "tab_errW_AV = desc(df[\"Error_rel_peso_AV_pct\"]).to_frame(\"Error_rel_peso_AV_pct\")\n",
    "\n",
    "tab_peso.round(3), tab_errW_AV.round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c7b74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cobertura acumulada por umbrales de error relativo (AV)\n",
    "thresholds = [5, 10, 15, 20]\n",
    "tab_cov = pd.DataFrame([{\n",
    "    \"Umbral (%)\": t,\n",
    "    \"% individuos (<=umbral)\": float((df[\"Error_rel_peso_AV_pct\"] <= t).mean() * 100),\n",
    "    \"N (<=umbral)\": int((df[\"Error_rel_peso_AV_pct\"] <= t).sum()),\n",
    "} for t in thresholds])\n",
    "\n",
    "tab_cov.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed67a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen por experimento (día)\n",
    "per = df.groupby(\"Experimento\")\n",
    "\n",
    "tab_per_metrology = per.agg({\n",
    "    \"Error_longitud_% (AV-REAL)\": [\"mean\", \"median\", lambda s: s.quantile(0.95)],\n",
    "    \"Error_anchura_% (AV-REAL)\": [\"mean\", \"median\", lambda s: s.quantile(0.95)],\n",
    "})\n",
    "tab_per_metrology.columns = [\"L_mean\", \"L_med\", \"L_P95\", \"A_mean\", \"A_med\", \"A_P95\"]\n",
    "\n",
    "tab_per_weight = per[\"Error_rel_peso_AV_pct\"].agg([\"count\", \"mean\", \"median\", lambda s: s.quantile(0.95), \"max\"])\n",
    "tab_per_weight.columns = [\"N\", \"Media_%\", \"Mediana_%\", \"P95_%\", \"Max_%\"]\n",
    "\n",
    "tab_per_metrology.round(4), tab_per_weight.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6acf30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error por rangos de peso real (robustez por tamaño)\n",
    "bins = [-np.inf, 2, 5, 10, np.inf]\n",
    "labels = [\"<2 g\", \"2–5 g\", \"5–10 g\", \">=10 g\"]\n",
    "\n",
    "df[\"Rango_peso\"] = pd.cut(df[COL_W], bins=bins, labels=labels)\n",
    "\n",
    "grp = df.groupby(\"Rango_peso\", observed=True)[\"Error_rel_peso_AV_pct\"]\n",
    "tab_bins = pd.DataFrame({\n",
    "    \"N\": grp.count().astype(int),\n",
    "    \"Media_%\": grp.mean(),\n",
    "    \"Mediana_%\": grp.median(),\n",
    "    \"P95_%\": grp.quantile(0.95),\n",
    "    \"Max_%\": grp.max(),\n",
    "}).round(2)\n",
    "\n",
    "tab_bins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4564a",
   "metadata": {},
   "source": [
    "## Figuras (generación reproducible)\n",
    "\n",
    "Se exportan las figuras a una carpeta local (`jbook_assets_exp`) para poder referenciarlas desde Jupyter-Book.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc5eee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generación de figuras ---\n",
    "out_dir = \"jbook_assets_exp\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Figura 4-1: distribución errores dimensionales\n",
    "plt.figure()\n",
    "plt.hist(df[\"Error_longitud_% (AV-REAL)\"], bins=40, alpha=0.7, label=\"Error longitud (%)\")\n",
    "plt.hist(df[\"Error_anchura_% (AV-REAL)\"], bins=40, alpha=0.7, label=\"Error anchura (%)\")\n",
    "plt.xlabel(\"Error relativo (%)\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.title(\"Distribución del error relativo en medidas AV vs REAL (5 experimentos)\")\n",
    "plt.legend()\n",
    "fig1 = os.path.join(out_dir, \"fig_4_1_error_dimensiones_5exp.png\")\n",
    "plt.tight_layout(); plt.savefig(fig1, dpi=200); plt.close()\n",
    "\n",
    "# Figura 4-2: histograma error de peso AV\n",
    "plt.figure()\n",
    "plt.hist(df[\"Error_rel_peso_AV_pct\"], bins=50)\n",
    "plt.xlabel(\"Error relativo del peso inferido (%)\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.title(\"Histograma del error relativo del peso inferido (dimensiones AV)\")\n",
    "fig2 = os.path.join(out_dir, \"fig_4_2_hist_error_peso_5exp.png\")\n",
    "plt.tight_layout(); plt.savefig(fig2, dpi=200); plt.close()\n",
    "\n",
    "# Figura 4-3: boxplot error por experimento\n",
    "plt.figure()\n",
    "data_box = [df.loc[df[\"Experimento\"] == i, \"Error_rel_peso_AV_pct\"].values for i in range(1, 6)]\n",
    "plt.boxplot(data_box, labels=[f\"E{i}\" for i in range(1, 6)], showfliers=True)\n",
    "plt.xlabel(\"Experimento (día)\")\n",
    "plt.ylabel(\"Error relativo del peso inferido (%)\")\n",
    "plt.title(\"Variabilidad inter-experimento del error de peso (AV)\")\n",
    "fig3 = os.path.join(out_dir, \"fig_4_3_boxplot_error_peso_por_experimento.png\")\n",
    "plt.tight_layout(); plt.savefig(fig3, dpi=200); plt.close()\n",
    "\n",
    "# Figura 4-4: boxplot por rango de peso\n",
    "plt.figure()\n",
    "data_box = [df.loc[df[\"Rango_peso\"] == lbl, \"Error_rel_peso_AV_pct\"].values for lbl in [\"<2 g\", \"2–5 g\", \"5–10 g\", \">=10 g\"]]\n",
    "plt.boxplot(data_box, labels=[\"<2 g\", \"2–5 g\", \"5–10 g\", \">=10 g\"], showfliers=True)\n",
    "plt.xlabel(\"Rango de peso real\")\n",
    "plt.ylabel(\"Error relativo del peso inferido (%)\")\n",
    "plt.title(\"Error de peso inferido (AV) por rangos de peso real\")\n",
    "fig4 = os.path.join(out_dir, \"fig_4_4_boxplot_error_por_rango_peso.png\")\n",
    "plt.tight_layout(); plt.savefig(fig4, dpi=200); plt.close()\n",
    "\n",
    "# Figura 4-5: scatter peso inferido vs real por experimento\n",
    "plt.figure()\n",
    "for i in range(1, 6):\n",
    "    sub = df[df[\"Experimento\"] == i]\n",
    "    plt.scatter(sub[COL_W], sub[\"Peso_inferido_AV_smear\"], s=10, label=f\"E{i}\", alpha=0.7)\n",
    "mx = float(np.nanmax([df[COL_W].max(), df[\"Peso_inferido_AV_smear\"].max()]))\n",
    "plt.plot([0, mx], [0, mx])\n",
    "plt.xlabel(\"Peso real (g)\")\n",
    "plt.ylabel(\"Peso inferido (g)\")\n",
    "plt.title(\"Peso inferido vs real por experimento (AV)\")\n",
    "plt.legend()\n",
    "fig5 = os.path.join(out_dir, \"fig_4_5_scatter_peso_real_vs_inferido_por_experimento.png\")\n",
    "plt.tight_layout(); plt.savefig(fig5, dpi=200); plt.close()\n",
    "\n",
    "# Figura 4-6: evolución media y P95 por experimento\n",
    "plt.figure()\n",
    "x = np.arange(1, 6)\n",
    "plt.plot(x, tab_per_weight[\"Media_%\"].values, marker=\"o\", label=\"Media (%)\")\n",
    "plt.plot(x, tab_per_weight[\"P95_%\"].values, marker=\"o\", label=\"P95 (%)\")\n",
    "plt.xlabel(\"Experimento (día)\")\n",
    "plt.ylabel(\"Error relativo (%)\")\n",
    "plt.title(\"Evolución de error de peso (media y P95) por experimento\")\n",
    "plt.legend()\n",
    "fig6 = os.path.join(out_dir, \"fig_4_6_media_p95_por_experimento.png\")\n",
    "plt.tight_layout(); plt.savefig(fig6, dpi=200); plt.close()\n",
    "\n",
    "[fig1, fig2, fig3, fig4, fig5, fig6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81992a39",
   "metadata": {},
   "source": [
    "## Discusión técnico-operativa (orientación CDTI)\n",
    "\n",
    "### Lecturas principales (resumen)\n",
    "\n",
    "- **Metrología (AV vs REAL):** los errores relativos de longitud y anchura permanecen contenidos y consistentes a lo largo de 5 días, lo que aporta evidencia de **repetibilidad del pipeline de visión** con configuración constante.\n",
    "- **Error de peso inferido (AV):** el error relativo presenta estabilidad central compatible con clasificación por tamaños. La dispersión en el extremo bajo (<2 g) es esperable por naturaleza geométrica y biológica.\n",
    "- **Repetibilidad inter-día:** la comparación por experimento (media/mediana/P95) permite argumentar **robustez temporal sin recalibración**, aspecto especialmente relevante para justificar TRL en memoria CDTI.\n",
    "- **Criterios de aceptación recomendados para clasificación:** mediana ≤10%, cobertura ≤10% ≥55–65%, P95 ≤25%, apoyado por QA para casos atípicos.\n",
    "\n",
    "### TRL (síntesis)\n",
    "Con la evidencia multi-día y el modelo único sin recalibración, la tecnología se sitúa en **TRL 6–7**, dependiendo del grado de equivalencia del banco de ensayo con la línea real (cadencia, manipulación, iluminación, etc.).\n",
    "\n",
    "### Recomendación para reforzar TRL 7→8\n",
    "- Añadir trazas operativas del entorno (parámetros de captura, control QA, incidencias)\n",
    "- Pilotos adicionales bajo variabilidad controlada (lote, densidad, iluminación)\n",
    "- Integración final con criterio de clasificación (umbrales por categoría) y medición de tasa de recaptura/“errores”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df60a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Opcional) Exportar un Excel enriquecido con columnas calculadas para auditoría/QA\n",
    "out_xlsx = \"Datos_experimentos_lenguado_enriquecido.xlsx\"\n",
    "df.to_excel(out_xlsx, index=False)\n",
    "out_xlsx\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
