{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc7b845c-abde-4dbc-a0fa-6e6c3265cf7f",
   "metadata": {},
   "source": [
    "# Sistema de visión artificial "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d11716b-d338-4ff3-8a32-dd7f1fd5349f",
   "metadata": {},
   "source": [
    "````{admonition} Resumen \n",
    ":class: tip\n",
    "\n",
    "El presente documento recoge los trabajos relativos al módulo de visión artificial de **FLATCLASS**. Este módulo es el responsable de la adquisición, normalizado, segmentación y extracción de las características mormométricas de los alevines de lenguado. \n",
    "\n",
    "**Entregable**: E1.2  \n",
    "**Versión**: 1.0  \n",
    "**Autor**: Javier Álvarez Osuna  \n",
    "**Email**: javier.osuna@fishfarmfeeder.com  \n",
    "**ORCID**: [0000-0001-7063-1279](https://orcid.org/0000-0001-7063-1279)  \n",
    "**Licencia**: CC-BY-4.0  \n",
    "**Código proyecto**: IG408M.2025.000.000072\n",
    "\n",
    "```{figure} .././assets/FLATCLASS_logo_publicidad.png\n",
    ":width: 100%\n",
    ":align: center\n",
    "```\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dde3a71-a54d-41e0-8588-a2bc6b72f388",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf47150-06b4-4c8c-9cce-1bfcc93bb259",
   "metadata": {},
   "source": [
    "Uno de los objetivos técnicos plantedos en **FLATCLASS* se centra en el Desarrollo e integración de un sistema de visión artificial de alta resolución que permita la captura precisa de imágenes de los alevines en tiempo real, asegurando una segmentación eficaz y el cálculo automático del área de superficie, longitud y anchura de cada individuo. El sistema automático desarrollado permite la medición sin contacto de las características morfométricas de lenguados (*Solea solea*) tales como la longitud total (L), la anchura corporal (A) y la superficie real (S) a partir de las imágenes fotográficas, obtenidas con una cámara Datalogic P22C 600-000 ML, mediante un algoritmo de procesado. Este algoritmo permite realizar la medición incluso cuando la cola del pez plano está deformada o cuando el pez se encuentra orientado de manera aleatoria, informando del nivel de fiabilidad de las mediciones cuando los resultados puedan persentar dudas. Este último aspecto es especialmente importante si tenemos en cuenta que el proceso de clasificación de juveniles se suele producir en ambientes de baja luminosidad y alta concentración de humedad que introduce importantes restricciones en la calidad de las imágenes obtenidas.\n",
    "\n",
    "El núcleo del sistema se sustenta en **GrabCut**, un método de segmentación de imágenes interactivo basado en teoría de grafos y optimización de cortes mínimos en campos aleatorios de Markov (MRF) definido por primera vez por [Rother et al.,](https://doi.org/10.1145/1015706.1015720) en 2004. El usuario define inicialmente un recuadro aproximado que contiene el pez, permitiendo al algoritmo estimar la distribución de color del primer plano y el fondo mediante modelos de mezcla gaussiana (Gaussian Mixture Models, GMM). Posteriormente, se plantea una función de energía que combina un término regional (basado en las probabilidades del GMM) y un término de continuidad espacial (prefiriendo regiones conectadas con etiquetas uniformes), la cual se minimiza mediante un corte en el grafo (graph cut). Este proceso se itera hasta converger en una segmentación refinada del pez frente al fondo [[Alsmadi et al., 2022](https://doi.org/10.1016/j.jksuci.2020.07.005].\n",
    "\n",
    "GrabCut ha sido objeto de mejoras continuas en los últimos años, incluyendo variantes que integran mapas de saliencia, superpíxeles o funciones de energía modificadas que permiten segmentaciones más precisas y automáticas [[Wang et al., 2023](https://doi.org/10.3390/math11081965)]. En el contexto acuícola, diferentes trabajos han aplicado algoritmos derivados de GrabCut (como versiones adaptadas o iterativas) para refinar la segmentación en imágenes de peces. Por ejemplo, [Huang et al., 2023](https://doi.org/10.11975/j.issn.1002-6819.2020.21.026) han desarrollado un sistema de visión binocular en acuicultura utilizó GrabCut adaptativo por contraste para segmentar peces bajo el agua, logrando un error porcentual medio en la medida de longitud de solo 0,9%. Asimismo, en el ámbito de la fenotipificación de peces de tilapia, GrabCut se ha empleado para afinar muestras en los bordes de segmentación, mejorando el IoU hasta un 81 % cuando se combina con redes profundas [[Feng et al., 2023](https://doi.org/10.3390/app13179635)].\n",
    "\n",
    "Para la extracción de morfometría de alevines de lenguado en fotografías tomadas desde arriba sobre una cinta transportadora, GrabCut es especialmente adecuado por varias razones clave. Primero, requiere mínima interacción (únicamente un recuadro inicial), lo cual es práctico en entornos productivos con alto flujo de muestras. Segundo, al basarse en modelos estadísticos de color y continuidad espacial, puede separar con precisión el pez del fondo uniforme de la cinta, incluso con variaciones de iluminación. Esto resulta esencial para cálculos fiables de longitud, anchura y superficie del pez. Finalmente, es computacionalmente eficiente y ya está implementado en bibliotecas comunes como OpenCV, lo que facilita su integración en un sistema automatizado de procesamiento de imágenes en planta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d29ad-b880-4f8f-b603-b36efe61e169",
   "metadata": {},
   "source": [
    "## Algoritmo extracción características morfométricas\n",
    "\n",
    "El flujograma del algortimo se recoge en la siguiente figura:\n",
    "\n",
    "```{figure} .././assets/Process_Img_Master.png\n",
    ":name: Figura_WP1_imagen.1\n",
    ":alt: Pipeline del sistema de extracción de características\n",
    ":width: 25%\n",
    ":align: center\n",
    "\n",
    "Pipeline del sistema de extracción de características\n",
    "```\n",
    "\n",
    "Como se puede apreciar el sistema está formado por siete módulos funcionales cada uno de ellos responsable de una función específica. En las siguientes secciones se estudia con mayor detalle cada uno de ellos y las tecnologías hardware-software usadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c00145e-8bed-49d4-9907-b10a333bb702",
   "metadata": {},
   "source": [
    "### M1 - Captura\n",
    "\n",
    "Este módulo es el responsable de la adquisición de las imágenes. Funcionalmente este módulo se sustenta sobre una barrera láser - a modo de trigger - a la entrada del canal (cinta transportadora) que cuando es interrumpida por el paso de un alevín activa la captura de la fotografía. La cámara envía la foto capturada a través del protocolo TCP al sistema de visión en dónde se lleva a cabo el flujo de acciones recogido en el siguiente diagrama.\n",
    "\n",
    "```{figure} .././assets/Modulo-1.png\n",
    ":name: Figura_WP1_imagen.2\n",
    ":alt: Flujograma del módulo de captura\n",
    ":width: 50%\n",
    ":align: center\n",
    "\n",
    "Flujograma del módulo de captura\n",
    "```\n",
    "\n",
    "El motor que controla el flujo de acciones se ha desarrollado sobre la base de Node-RED. Node-RED es una herramienta de programación visual basada en flujos desarrollada inicialmente por IBM, que permite integrar dispositivos, APIs y servicios mediante nodos configurables. Su arquitectura está construida sobre Node.js, lo que le proporciona un alto rendimiento y la capacidad de ejecutar procesos en tiempo real sobre hardware ligero (desde servidores industriales hasta dispositivos embebidos como Raspberry Pi). Los flujos en Node-RED se representan gráficamente, facilitando la implementación de sistemas complejos en entornos de IoT e Industria 4.0. Además, su ecosistema de nodos permite la integración directa con protocolos industriales (p. ej., MQTT, OPC-UA, Modbus, TCP-UDP), bases de datos, sistemas de control (PLC) y librerías externas en Python o C++, lo que lo convierte en una plataforma idónea para la adquisición y procesamiento de datos heterogéneos.\n",
    "\n",
    "En el contexto del módulo de captura de imágenes descrito, Node-RED ofrece ventajas críticas: permite orquestar la señal de disparo proveniente de una barrera, gestiona la adquisición de la imagen junto con sus metadatos (timestamp, ID, parámetros de cámara...) y aplicar rutinas de validación para garantizar la integridad del frame capturado. El hecho adicional de poder programar funciones personalizadas en JavaScript o integrar scripts externos en Python, permite ejecutar código necesario para validar si la imagen es utilizable (`¿Frame válido?`) antes de enviarla a etapas posteriores de procesado, minimizando errores y pérdidas de información. El flujo responsable de la adquisición y los nodos implicados se refleja en la siguiente figura.\n",
    "\n",
    "```{figure} .././assets/Modulo-1_nodered.png\n",
    ":name: Figura_WP1_imagen.3\n",
    ":alt: Flujo de acciones Node-RED\n",
    ":width: 75%\n",
    ":align: center\n",
    "\n",
    "Flujo de acciones responsable de la funcionalidad del módulo de captura de imagen\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4063111-c954-4873-83f6-d0ef8f3f3bf4",
   "metadata": {},
   "source": [
    "### M2 - Calibración\n",
    "\n",
    "Para poder extraer las dimensiones reales (mm) de la longitud, anchura y altura es necesario que el sistema disponga de algún tipo de calibración. Para ello la forma más rápida es disponer de un damero (Checkerboard) de dimensiones exactas y conocidas como el de la figura, en el que cada una de las inserciones internas mide exactamente 10 mm de lado.\n",
    "\n",
    "```{figure} .././assets/checkerboard_10x10.png\n",
    ":name: Figura_WP1_imagen.4\n",
    ":alt: Checkerboard\n",
    ":width: 75%\n",
    ":align: center\n",
    "\n",
    "Checkerdoard (damero) para calibración\n",
    "```\n",
    "Si $𝐿_{px}$ es la longitud medida en píxeles de un objeto cuya longitud real $L_{mm}$ es conocida (10 mm en nuestro damero), la escala se define como:\n",
    "\n",
    "$$\n",
    "𝑠[mm/px]=\\dfrac{L_{mm}}{𝐿_{px}}\n",
    "$$\n",
    "  \n",
    "Para robustez, se usa la mediana de múltiples aristas horizontales y verticales [[Zang, Z., 2020](https://doi.org/10.1109/34.888718)]. La incertidumbre relativa de primer orden es:\n",
    "$$\n",
    "\\left(\\frac{\\sigma_s}{s}\\right)^2 \\;\\approx\\; \n",
    "\\left(\\frac{\\sigma_{L_{\\text{mm}}}}{L_{\\text{mm}}}\\right)^2 \\;+\\; \n",
    "\\left(\\frac{\\sigma_{L_{\\text{px}}}}{L_{\\text{px}}}\\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bb5956-d7dd-4567-9d0b-ea44e9a6d225",
   "metadata": {},
   "source": [
    "El flujo UML que resuelve la calibración es el siguiente:\n",
    "\n",
    "```{figure} .././assets/calibracion.png\n",
    ":name: Figura_WP1_imagen.5\n",
    ":alt: UML Calibracion\n",
    ":width: 75%\n",
    ":align: center\n",
    "\n",
    "UML proceso de calibración\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f286c844-b5cf-48f0-81d9-399dc2e6c53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\javie\\workspaces\\base12\\lib\\site-packages (from opencv-python) (2.1.3)\n",
      "Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "   ---------------------------------------- 0.0/39.0 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 6.8/39.0 MB 38.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 16.3/39.0 MB 41.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 24.1/39.0 MB 40.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 26.0/39.0 MB 32.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 32.0/39.0 MB 31.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/39.0 MB 32.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.0/39.0 MB 31.8 MB/s  0:00:01\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.12.0.88\n"
     ]
    }
   ],
   "source": [
    "## INSTALACION DE LIBRERIAS\n",
    "\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf89649-b6ad-4b4a-a121-104a80f23048",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT Y UTILIDAES DE E/S\n",
    "\n",
    "# Importa librerías y define utilidades para leer/escribir JSON con seguridad.\n",
    "\n",
    "import json\n",
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Any, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def load_json(path: Path) -> Optional[dict]:\n",
    "    \"\"\"Carga un JSON si existe; devuelve None si no existe.\"\"\"\n",
    "    if not path.exists():\n",
    "        return None\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(path: Path, data: dict) -> None:\n",
    "    \"\"\"Guarda un dict como JSON (UTF-8, con indentado) y crea carpetas si no existen.\"\"\"\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f45cab9f-aaca-49c5-b057-61bce51bc0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONFIG\n",
    "\n",
    "# fija rutas y parámetros del patrón para el damero\n",
    "\n",
    "# === CONFIG (ajustada a tu damero generado) ===================================\n",
    "CALIB_FILE = Path(\"./calibracion_px_mm.json\")\n",
    "\n",
    "# Patrón de referencia: DAMERO 10x10 cuadrados => 9x9 intersecciones internas\n",
    "CHECKERBOARD_SQUARE_MM = 10.0\n",
    "CHECKERBOARD_SQUARES_COLS = 10   # número de cuadrados horizontales\n",
    "CHECKERBOARD_SQUARES_ROWS = 10   # número de cuadrados verticales\n",
    "CHECKERBOARD_INTERNAL_COLS = CHECKERBOARD_SQUARES_COLS - 1  # 9 intersecciones internas\n",
    "CHECKERBOARD_INTERNAL_ROWS = CHECKERBOARD_SQUARES_ROWS - 1  # 9 intersecciones internas\n",
    "\n",
    "# Agregación robusta de distancias entre esquinas: \"median\" o \"mean\"\n",
    "AGGREGATION = \"median\"\n",
    "\n",
    "# Usa el damero de referencia.\n",
    "IMG_PATH = Path(\".././assets/checkerboard_10x10.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "667663d3-d641-4b53-bce2-951653e575fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ESTRUCTURA DE CALIBRACION Y PERSISTENCIA\n",
    "\n",
    "# Define la estructura (dataclass) que se guardará en JSON y las funciones de lectura/escritura\n",
    "\n",
    "@dataclass\n",
    "class Calibration:\n",
    "    \"\"\"\n",
    "    Estructura persistente de calibración.\n",
    "    - mm_per_px: escala (milímetros por píxel).\n",
    "    - method: método usado (\"checkerboard\").\n",
    "    - meta: metadatos/diagnósticos (estadísticos de distancias en píxeles, etc.).\n",
    "    \"\"\"\n",
    "    mm_per_px: float\n",
    "    method: str\n",
    "    meta: Dict[str, Any]\n",
    "\n",
    "def load_calibration(path: Path) -> Optional[Calibration]:\n",
    "    \"\"\"Lee la calibración desde JSON; devuelve None si no existe o si hay formato inválido.\"\"\"\n",
    "    data = load_json(path)\n",
    "    if data is None:\n",
    "        return None\n",
    "    try:\n",
    "        return Calibration(\n",
    "            mm_per_px=float(data[\"mm_per_px\"]),\n",
    "            method=str(data[\"method\"]),\n",
    "            meta=dict(data[\"meta\"]),\n",
    "        )\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def save_calibration(path: Path, cal: Calibration) -> None:\n",
    "    \"\"\"Persistencia de calibración a JSON.\"\"\"\n",
    "    save_json(path, asdict(cal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3797893a-a7c6-4613-9487-18858c42f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DETECCIÓN DEL DAMERO Y CÁLCULO mm/px\n",
    "\n",
    "def detect_checkerboard_scale(\n",
    "    img_bgr: np.ndarray,\n",
    "    cols_internal: int,\n",
    "    rows_internal: int,\n",
    "    square_mm: float,\n",
    "    aggregation: str = \"median\"\n",
    ") -> Optional[Tuple[float, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Detecta un damero de (cols_internal x rows_internal) intersecciones internas.\n",
    "    Calcula mm/px usando la mediana (por defecto) de distancias entre esquinas adyacentes.\n",
    "\n",
    "    Devuelve: (mm_per_px, diagnostics) si detecta; None si no detecta.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flags = cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_NORMALIZE_IMAGE\n",
    "    found, corners = cv2.findChessboardCorners(gray, (cols_internal, rows_internal), flags)\n",
    "\n",
    "    if not found or corners is None:\n",
    "        return None\n",
    "\n",
    "    # Refinamiento subpíxel\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 50, 1e-4)\n",
    "    corners = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "    corners = corners.reshape(-1, 2)  # N x 2\n",
    "\n",
    "    # Distancias horizontales\n",
    "    horiz = []\n",
    "    for r in range(rows_internal):\n",
    "        for c in range(cols_internal - 1):\n",
    "            i = r * cols_internal + c\n",
    "            j = r * cols_internal + (c + 1)\n",
    "            d = np.linalg.norm(corners[i] - corners[j])\n",
    "            if d > 0:\n",
    "                horiz.append(d)\n",
    "\n",
    "    # Distancias verticales\n",
    "    vert = []\n",
    "    for r in range(rows_internal - 1):\n",
    "        for c in range(cols_internal):\n",
    "            i = r * cols_internal + c\n",
    "            j = (r + 1) * cols_internal + c\n",
    "            d = np.linalg.norm(corners[i] - corners[j])\n",
    "            if d > 0:\n",
    "                vert.append(d)\n",
    "\n",
    "    dists = np.array(horiz + vert, dtype=float)\n",
    "    if dists.size == 0:\n",
    "        return None\n",
    "\n",
    "    # px por cuadrado (mediana por robustez ante outliers)\n",
    "    px_per_square = np.median(dists) if aggregation == \"median\" else np.mean(dists)\n",
    "    mm_per_px     = square_mm / px_per_square\n",
    "\n",
    "    diagnostics = {\n",
    "        \"pattern\": \"checkerboard\",\n",
    "        \"internal_cols\": int(cols_internal),\n",
    "        \"internal_rows\": int(rows_internal),\n",
    "        \"square_mm\": float(square_mm),\n",
    "        \"edges_count\": int(dists.size),\n",
    "        \"px_per_square_summary\": {\n",
    "            \"mean\": float(np.mean(dists)),\n",
    "            \"median\": float(np.median(dists)),\n",
    "            \"std\": float(np.std(dists, ddof=1)) if dists.size > 1 else 0.0\n",
    "        },\n",
    "        \"aggregation\": aggregation\n",
    "    }\n",
    "    return mm_per_px, diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e85cf997-3817-491b-b56b-bb0a42d8ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OVERLAY DE CONTROL VISUAL Y .png DIAGNÓSTICO\n",
    "\n",
    "# Su función es verificar y documentar que la detección ha sido correcta.\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def overlay_checkerboard_and_save(\n",
    "    img_path: Path,\n",
    "    out_path: Path,\n",
    "    cols_internal: int,\n",
    "    rows_internal: int,\n",
    "    mm_per_px: float = None,\n",
    "    draw_rect: bool = True\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Dibuja esquinas del damero y anota mm/px (si disponible). Guarda PNG.\n",
    "    Devuelve dict con 'ok' y detalles/motivo de fallo.\n",
    "    \"\"\"\n",
    "    if not img_path.exists():\n",
    "        return {\"ok\": False, \"motivo\": f\"Imagen no encontrada: {str(img_path)}\"}\n",
    "\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        return {\"ok\": False, \"motivo\": f\"No se pudo abrir la imagen: {str(img_path)}\"}\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    flags = cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_NORMALIZE_IMAGE\n",
    "    found, corners = cv2.findChessboardCorners(gray, (cols_internal, rows_internal), flags)\n",
    "\n",
    "    vis = img.copy()\n",
    "    if not found or corners is None:\n",
    "        cv2.putText(vis, \"Checkerboard NO detectado\", (20, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        ok = cv2.imwrite(str(out_path), vis)\n",
    "        return {\"ok\": bool(ok), \"motivo\": \"No se detecto el damero; PNG guardado con aviso.\", \"out\": str(out_path)}\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 50, 1e-4)\n",
    "    corners = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "\n",
    "    cv2.drawChessboardCorners(vis, (cols_internal, rows_internal), corners, found)\n",
    "\n",
    "    if draw_rect:\n",
    "        pts = corners.reshape(-1, 2)\n",
    "        x_min, y_min = np.floor(pts.min(axis=0)).astype(int)\n",
    "        x_max, y_max = np.ceil(pts.max(axis=0)).astype(int)\n",
    "        cv2.rectangle(vis, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n",
    "\n",
    "    y0 = 30\n",
    "    cv2.putText(vis, f\"Damero {cols_internal}x{rows_internal} (intersecciones)\", (20, y0),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (50, 220, 50), 2, cv2.LINE_AA)\n",
    "    y0 += 30\n",
    "    if mm_per_px is not None:\n",
    "        cv2.putText(vis, f\"Escala: {mm_per_px:.6f} mm/px\", (20, y0),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (50, 220, 50), 2, cv2.LINE_AA)\n",
    "        y0 += 30\n",
    "    cv2.putText(vis, f\"Timestamp: {datetime.now().isoformat(timespec='seconds')}\", (20, y0),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2, cv2.LINE_AA)\n",
    "\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    ok = cv2.imwrite(str(out_path), vis)\n",
    "    return {\"ok\": bool(ok), \"motivo\": \"\" if ok else \"cv2.imwrite fallo\", \"out\": str(out_path)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e03127df-2f06-4a46-8614-cb46dc9b68d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EJECUTOR\n",
    "\n",
    "# implementa literalmente el diagrama de decisiones: \n",
    "# - usar calibración vigente (permanente) salvo que el usuario fuerce recalibración;\n",
    "# - si no hay calibración o se fuerza, intenta detectar y calcular; \n",
    "# - si falla, `sin_escala`\n",
    "\n",
    "def run_calibration_pipeline_checkerboard(\n",
    "    calib_file: Path,\n",
    "    img_path: Path,\n",
    "    cols_internal: int,\n",
    "    rows_internal: int,\n",
    "    square_mm: float,\n",
    "    aggregation: str = \"median\",\n",
    "    force_recalibrate: bool = False\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    UML “M2 - Calibración de escala”:\n",
    "\n",
    "    if (¿Calibración vigente?) then (Sí)\n",
    "        :Usar escala px→mm guardada;\n",
    "    else (No)\n",
    "        :Detectar patrón referencia;\n",
    "        if (¿Detectado?) then (Sí)\n",
    "            :Calcular escala px→mm; (y guardar)\n",
    "        else (No)\n",
    "            :Marcar sin_escala;\n",
    "\n",
    "    'Vigente' = existe calibración en disco y NO se fuerza recalibración.\n",
    "    \"\"\"\n",
    "    # 1) ¿Calibración 'vigente'?\n",
    "    if not force_recalibrate:\n",
    "        cal = load_calibration(calib_file)\n",
    "        if cal is not None and cal.method == \"checkerboard\":\n",
    "            return {\n",
    "                \"estado\": \"vigente\",\n",
    "                \"mm_per_px\": cal.mm_per_px,\n",
    "                \"method\": cal.method,\n",
    "                \"meta\": cal.meta\n",
    "            }\n",
    "\n",
    "    # 2) No vigente (o se fuerza) -> Detectar patrón referencia\n",
    "    if not img_path.exists():\n",
    "        return {\"estado\": \"sin_escala\", \"motivo\": f\"Imagen no encontrada: {str(img_path)}\"}\n",
    "\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        return {\"estado\": \"sin_escala\", \"motivo\": f\"No se pudo abrir la imagen: {str(img_path)}\"}\n",
    "\n",
    "    res = detect_checkerboard_scale(\n",
    "        img_bgr=img,\n",
    "        cols_internal=cols_internal,\n",
    "        rows_internal=rows_internal,\n",
    "        square_mm=square_mm,\n",
    "        aggregation=aggregation\n",
    "    )\n",
    "\n",
    "    # 3) ¿Detectado?\n",
    "    if res is None:\n",
    "        return {\"estado\": \"sin_escala\", \"motivo\": \"No se detectó el damero en la imagen\"}\n",
    "\n",
    "    # 4) Calcular escala y guardar\n",
    "    mm_per_px, diag = res\n",
    "    cal = Calibration(\n",
    "        mm_per_px=float(mm_per_px),\n",
    "        method=\"checkerboard\",\n",
    "        meta={\"diagnostics\": diag}\n",
    "    )\n",
    "    save_calibration(calib_file, cal)\n",
    "\n",
    "    return {\n",
    "        \"estado\": \"recalibrado\",\n",
    "        \"mm_per_px\": cal.mm_per_px,\n",
    "        \"method\": cal.method,\n",
    "        \"meta\": cal.meta\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5444047-8e8d-4397-84d6-1fab6b9a2105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estado': 'vigente',\n",
       " 'mm_per_px': 0.125,\n",
       " 'method': 'checkerboard',\n",
       " 'meta': {'diagnostics': {'pattern': 'checkerboard',\n",
       "   'internal_cols': 9,\n",
       "   'internal_rows': 9,\n",
       "   'square_mm': 10.0,\n",
       "   'edges_count': 144,\n",
       "   'px_per_square_summary': {'mean': 80.0, 'median': 80.0, 'std': 0.0},\n",
       "   'aggregation': 'median'}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## EJECUCION NORMAL\n",
    "\n",
    "result = run_calibration_pipeline_checkerboard(\n",
    "    calib_file=CALIB_FILE,\n",
    "    img_path=IMG_PATH,\n",
    "    cols_internal=CHECKERBOARD_INTERNAL_COLS,\n",
    "    rows_internal=CHECKERBOARD_INTERNAL_ROWS,\n",
    "    square_mm=CHECKERBOARD_SQUARE_MM,          \n",
    "    aggregation=AGGREGATION,                   \n",
    "    force_recalibrate=False\n",
    ")\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1f07de8-5b48-4a38-bb75-fdb083c76cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mm_per_px': 0.125,\n",
       " 'px_per_mm': 8.0,\n",
       " 'method': 'checkerboard',\n",
       " 'pattern': 'checkerboard',\n",
       " 'uncertainty_sigma_mm_per_px': np.float64(0.0),\n",
       " 'ci95_mm_per_px': (np.float64(0.125), np.float64(0.125)),\n",
       " 'diagnostics_available': True,\n",
       " 'details': {'center_px': 80.0,\n",
       "  'std_px_edges': 0.0,\n",
       "  'se_px_used': np.float64(0.0),\n",
       "  'n_edges': 144,\n",
       "  'aggregation': 'median',\n",
       "  'square_mm': 10.0,\n",
       "  'sigma_square_mm': 0.0,\n",
       "  'rel_uncertainty_s': np.float64(0.0)}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## VALIDACIÓN NUMÉRICA\n",
    "\n",
    "# Lee la calibración y reporta mm/px y px/mm estimado la incertidumbre\n",
    "\n",
    "def load_calibration_dict(path: Path) -> dict:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"No existe el archivo de calibración: {path}\")\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def validation_report(calib_json: dict, assume_square_exact_mm=True, square_sigma_mm=0.0):\n",
    "    \"\"\"\n",
    "    Reporta mm/px, px/mm e incertidumbre estimada.\n",
    "    - Si conoces la tolerancia del patrón (p.ej. ±0.02 mm), usa assume_square_exact_mm=False y square_sigma_mm=0.02.\n",
    "    \"\"\"\n",
    "    mm_per_px = float(calib_json[\"mm_per_px\"])\n",
    "    px_per_mm = 1.0 / mm_per_px if mm_per_px > 0 else np.nan\n",
    "\n",
    "    diag = calib_json.get(\"meta\", {}).get(\"diagnostics\", {})\n",
    "    pattern = diag.get(\"pattern\", \"checkerboard\")\n",
    "    px_sum = diag.get(\"px_per_square_summary\", {})\n",
    "    aggregation = diag.get(\"aggregation\", \"median\")\n",
    "    square_mm = float(diag.get(\"square_mm\", np.nan))\n",
    "\n",
    "    center_px = px_sum.get(\"median\" if aggregation == \"median\" else \"mean\", None)\n",
    "    std_px = px_sum.get(\"std\", None)\n",
    "    n_edges = diag.get(\"edges_count\", None)\n",
    "\n",
    "    sigma_s = None\n",
    "    ci95 = (None, None)\n",
    "    details = {}\n",
    "\n",
    "    if center_px and std_px is not None and center_px > 0:\n",
    "        sigma_square = 0.0 if assume_square_exact_mm else float(square_sigma_mm)\n",
    "\n",
    "        # Error estándar del estimador: media vs mediana\n",
    "        if n_edges and n_edges > 1:\n",
    "            if aggregation == \"mean\":\n",
    "                se_px = std_px / np.sqrt(n_edges)\n",
    "            else:\n",
    "                se_px = 1.253 * std_px / np.sqrt(n_edges)  # aprox. SE de la mediana\n",
    "        else:\n",
    "            se_px = std_px\n",
    "\n",
    "        # Propagación de errores (1er orden)\n",
    "        rel_sq = (sigma_square / square_mm)**2 if (square_mm and square_mm > 0) else 0.0\n",
    "        rel_px = (se_px / center_px)**2\n",
    "        rel_s  = np.sqrt(rel_sq + rel_px)\n",
    "\n",
    "        sigma_s = rel_s * mm_per_px\n",
    "        ci95 = (mm_per_px - 1.96 * sigma_s, mm_per_px + 1.96 * sigma_s)\n",
    "\n",
    "        details = {\n",
    "            \"center_px\": center_px,\n",
    "            \"std_px_edges\": std_px,\n",
    "            \"se_px_used\": se_px,\n",
    "            \"n_edges\": n_edges,\n",
    "            \"aggregation\": aggregation,\n",
    "            \"square_mm\": square_mm,\n",
    "            \"sigma_square_mm\": sigma_square,\n",
    "            \"rel_uncertainty_s\": rel_s\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"mm_per_px\": mm_per_px,\n",
    "        \"px_per_mm\": px_per_mm,\n",
    "        \"method\": calib_json.get(\"method\", \"\"),\n",
    "        \"pattern\": pattern,\n",
    "        \"uncertainty_sigma_mm_per_px\": sigma_s,\n",
    "        \"ci95_mm_per_px\": ci95,\n",
    "        \"diagnostics_available\": (std_px is not None),\n",
    "        \"details\": details\n",
    "    }\n",
    "\n",
    "# === Ejecutar validación ===\n",
    "cal_data = load_calibration_dict(CALIB_FILE)\n",
    "report = validation_report(cal_data, assume_square_exact_mm=True, square_sigma_mm=0.0)\n",
    "report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a35993c-a326-49f3-9457-96cf4d0c64dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## UTILIDADES DE CONVERSION\n",
    "\n",
    "# Funciones auxiliares para convertir medidas en el pipeline de visión.\n",
    "\n",
    "def get_mm_per_px(calib_file: Path = CALIB_FILE) -> float:\n",
    "    \"\"\"Devuelve la escala mm/px leída del archivo de calibración.\"\"\"\n",
    "    cal = load_calibration(calib_file)\n",
    "    if cal is None:\n",
    "        raise RuntimeError(f\"No hay calibración guardada en {calib_file}. Ejecuta el pipeline primero.\")\n",
    "    return float(cal.mm_per_px)\n",
    "\n",
    "def px_to_mm(value_px: float, mm_per_px: float) -> float:\n",
    "    \"\"\"Convierte longitudes en píxeles a milímetros.\"\"\"\n",
    "    return float(value_px) * float(mm_per_px)\n",
    "\n",
    "def mm_to_px(value_mm: float, mm_per_px: float) -> float:\n",
    "    \"\"\"Convierte longitudes en milímetros a píxeles.\"\"\"\n",
    "    if mm_per_px <= 0:\n",
    "        raise ValueError(\"mm_per_px debe ser positivo.\")\n",
    "    return float(value_mm) / float(mm_per_px)\n",
    "\n",
    "# Ejemplos:\n",
    "# mmpp = get_mm_per_px()\n",
    "# L_mm = px_to_mm(123.4, mmpp)\n",
    "# print(\"Longitud en mm:\", L_mm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecf57f1-ac21-405d-931c-334e8b67179b",
   "metadata": {},
   "source": [
    "Un ejemplo de uso de estas funciones sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd96334d-e549-4863-908f-99773d9cafa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escala actual mm/px: 0.125\n",
      "\n",
      "Longitud en milímetros de 125 px: 15.625\n"
     ]
    }
   ],
   "source": [
    "print(f\"Escala actual mm/px: {get_mm_per_px()}\\n\")\n",
    "print(f\"Longitud en milímetros de 125 px: {px_to_mm(125, get_mm_per_px())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f40015ad-8011-45f8-9149-0b8a82912a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## UTILIDAD DE RECALIBRACION FORZADA CON .png DE DIAGNOSTICO\n",
    "\n",
    "# fuerza recálculo con el damero sintético y genera un PNG de control visual.\n",
    "\n",
    "def recalibrar_y_generar_png(\n",
    "    calib_file: Path,\n",
    "    img_path: Path,\n",
    "    cols_internal: int,\n",
    "    rows_internal: int,\n",
    "    square_mm: float,\n",
    "    aggregation: str = \"median\",\n",
    "    out_png: Path = Path(\"./diagnosticos/diagnostico_calibracion.png\"),\n",
    "    timestamp_bgr: tuple = (0, 0, 255),   # ROJO en BGR (por defecto)\n",
    "    box_bgr: tuple = (255, 0, 0),         # Azul para rectángulo envolvente\n",
    "    text_bgr: tuple = (50, 220, 50)       # Verde para textos informativos\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Fuerza la recalibración usando el damero de 'img_path' y genera un PNG de diagnóstico.\n",
    "    - Dibuja esquinas detectadas, rectángulo envolvente y anota mm/px.\n",
    "    - Pinta el timestamp en ROJO (BGR=(0,0,255) por defecto).\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    calib_file : Path\n",
    "        Ruta del JSON donde se guardará la calibración (mm/px, meta).\n",
    "    img_path : Path\n",
    "        Ruta de la imagen del damero (10x10 → 9x9 intersecciones internas).\n",
    "    cols_internal, rows_internal : int\n",
    "        Intersecciones internas del damero (p.ej., 9x9 para 10x10 cuadrados).\n",
    "    square_mm : float\n",
    "        Tamaño físico del lado de cada cuadrado (mm), p.ej. 10.0.\n",
    "    aggregation : {\"median\",\"mean\"}\n",
    "        Agregación para estimar px por cuadrado (robusta por defecto: \"median\").\n",
    "    out_png : Path\n",
    "        Ruta de salida del PNG de diagnóstico.\n",
    "    timestamp_bgr : tuple\n",
    "        Color BGR para el timestamp (rojo por defecto).\n",
    "    box_bgr : tuple\n",
    "        Color BGR del rectángulo envolvente (azul por defecto).\n",
    "    text_bgr : tuple\n",
    "        Color BGR para textos informativos (verde por defecto).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict con claves:\n",
    "      - \"recal\": dict con el resultado de la recalibración (estado, mm_per_px, meta)\n",
    "      - \"overlay\": dict con {\"ok\": bool, \"out\": str(ruta_png)} (o motivo de fallo)\n",
    "      - \"mm_per_px\": float o None (si no disponible)\n",
    "      - \"estado\": str (e.g., \"recalibrado\", \"vigente\", \"sin_escala\")\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "\n",
    "    # 1) Forzar recalibración (usa la función del pipeline del notebook)\n",
    "    recal = run_calibration_pipeline_checkerboard(\n",
    "        calib_file=calib_file,\n",
    "        img_path=img_path,\n",
    "        cols_internal=cols_internal,\n",
    "        rows_internal=rows_internal,\n",
    "        square_mm=square_mm,\n",
    "        aggregation=aggregation,\n",
    "        force_recalibrate=True\n",
    "    )\n",
    "\n",
    "    # 2) Preparar overlay (detectar de nuevo para dibujar) con TIMESTAMP ROJO\n",
    "    if not img_path.exists():\n",
    "        return {\n",
    "            \"recal\": recal,\n",
    "            \"overlay\": {\"ok\": False, \"motivo\": f\"Imagen no encontrada: {str(img_path)}\"},\n",
    "            \"mm_per_px\": float(recal[\"mm_per_px\"]) if isinstance(recal, dict) and \"mm_per_px\" in recal else None,\n",
    "            \"estado\": recal.get(\"estado\") if isinstance(recal, dict) else None\n",
    "        }\n",
    "\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        return {\n",
    "            \"recal\": recal,\n",
    "            \"overlay\": {\"ok\": False, \"motivo\": f\"No se pudo abrir la imagen: {str(img_path)}\"},\n",
    "            \"mm_per_px\": float(recal[\"mm_per_px\"]) if isinstance(recal, dict) and \"mm_per_px\" in recal else None,\n",
    "            \"estado\": recal.get(\"estado\") if isinstance(recal, dict) else None\n",
    "        }\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    flags = cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_NORMALIZE_IMAGE\n",
    "    found, corners = cv2.findChessboardCorners(gray, (cols_internal, rows_internal), flags)\n",
    "\n",
    "    vis = img.copy()\n",
    "    if not found or corners is None:\n",
    "        cv2.putText(\n",
    "            vis, \"Checkerboard NO detectado\", (20, 40),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2, cv2.LINE_AA\n",
    "        )\n",
    "        # timestamp en rojo aunque no haya detección\n",
    "        cv2.putText(\n",
    "            vis, f\"Timestamp: {datetime.now().isoformat(timespec='seconds')}\", (20, 80),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.7, timestamp_bgr, 2, cv2.LINE_AA\n",
    "        )\n",
    "    else:\n",
    "        # Refinar esquinas y dibujarlas\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 50, 1e-4)\n",
    "        corners = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "        cv2.drawChessboardCorners(vis, (cols_internal, rows_internal), corners, found)\n",
    "\n",
    "        # Rectángulo envolvente\n",
    "        pts = corners.reshape(-1, 2)\n",
    "        x_min, y_min = np.floor(pts.min(axis=0)).astype(int)\n",
    "        x_max, y_max = np.ceil(pts.max(axis=0)).astype(int)\n",
    "        cv2.rectangle(vis, (x_min, y_min), (x_max, y_max), box_bgr, 2)\n",
    "\n",
    "        # Textos informativos (verde por defecto)\n",
    "        y0 = 30\n",
    "        cv2.putText(\n",
    "            vis, f\"Damero {cols_internal}x{rows_internal} (intersecciones)\", (20, y0),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.8, text_bgr, 2, cv2.LINE_AA\n",
    "        )\n",
    "        y0 += 30\n",
    "        mmpp = float(recal[\"mm_per_px\"]) if isinstance(recal, dict) and \"mm_per_px\" in recal else None\n",
    "        if mmpp is not None:\n",
    "            cv2.putText(\n",
    "                vis, f\"Escala: {mmpp:.6f} mm/px\", (20, y0),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, text_bgr, 2, cv2.LINE_AA\n",
    "            )\n",
    "            y0 += 30\n",
    "\n",
    "        # TIMESTAMP en ROJO\n",
    "        cv2.putText(\n",
    "            vis, f\"Timestamp: {datetime.now().isoformat(timespec='seconds')}\", (20, y0),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.7, timestamp_bgr, 2, cv2.LINE_AA\n",
    "        )\n",
    "\n",
    "    # 3) Guardar PNG\n",
    "    out_png.parent.mkdir(parents=True, exist_ok=True)\n",
    "    ok = cv2.imwrite(str(out_png), vis)\n",
    "\n",
    "    return {\n",
    "        \"recal\": recal,\n",
    "        \"overlay\": {\"ok\": bool(ok), \"out\": str(out_png) if ok else None},\n",
    "        \"mm_per_px\": float(recal[\"mm_per_px\"]) if isinstance(recal, dict) and \"mm_per_px\" in recal else None,\n",
    "        \"estado\": recal.get(\"estado\") if isinstance(recal, dict) else None\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c18748-70ff-4e12-87a2-509019a6da68",
   "metadata": {},
   "source": [
    "Un ejemplo de uso de esta función de recalibrado forzado sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ea70d0e-fe6f-490a-8add-45ed0296838b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recal': {'estado': 'recalibrado',\n",
       "  'mm_per_px': 0.125,\n",
       "  'method': 'checkerboard',\n",
       "  'meta': {'diagnostics': {'pattern': 'checkerboard',\n",
       "    'internal_cols': 9,\n",
       "    'internal_rows': 9,\n",
       "    'square_mm': 10.0,\n",
       "    'edges_count': 144,\n",
       "    'px_per_square_summary': {'mean': 80.0, 'median': 80.0, 'std': 0.0},\n",
       "    'aggregation': 'median'}}},\n",
       " 'overlay': {'ok': True, 'out': 'diagnosticos\\\\diagnostico_calibracion.png'},\n",
       " 'mm_per_px': 0.125,\n",
       " 'estado': 'recalibrado'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = recalibrar_y_generar_png(\n",
    "    calib_file=CALIB_FILE,\n",
    "    img_path=IMG_PATH,\n",
    "    cols_internal=CHECKERBOARD_INTERNAL_COLS,  # 9\n",
    "    rows_internal=CHECKERBOARD_INTERNAL_ROWS,  # 9\n",
    "    square_mm=CHECKERBOARD_SQUARE_MM,          # 10.0\n",
    "    aggregation=AGGREGATION,                   # \"median\"\n",
    "    out_png=Path(\"./diagnosticos/diagnostico_calibracion.png\")\n",
    ")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be586f16-4646-4893-8164-1b8b541cae74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
